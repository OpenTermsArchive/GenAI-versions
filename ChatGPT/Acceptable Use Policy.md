Effective: October 29, 2025

Usage policies
==============

We aim for our tools to be used safely and responsibly, while maximizing your control over how you use them. In building our Usage Policies, we keep a few important things in mind.

**We empower users to innovate with AI**. We build AI products that maximize helpfulness and freedom, while ensuring safety. Usage Policies are just one way we set clear expectations for the use of our products within a broader safety ecosystem that sets responsible guardrails across our services. You can [learn more](https://openai.com/safety/how-we-think-about-safety-alignment/) about our safety approach and [our commitment to](https://openai.com/index/introducing-the-model-spec/) customizability, transparency, and intellectual freedom to explore, debate, and create with AI.

**Responsible use is a shared priority**. We assume the very best of our users. Our [terms and policies](https://openai.com/policies/)—including these Usage Policies—set a reasonable bar for acceptable use. Our rules are no substitute for legal requirements, professional duties, or ethical obligations that should influence how people use AI. We hold people accountable for inappropriate use of our services, and breaking or circumventing our rules and safeguards may mean you lose access to our systems or experience other penalties.

**We build with safety first**. We [monitor and enforce](https://openai.com/transparency-and-content-moderation/) policies with privacy safeguards in place and clear review processes. We give developers practical [moderation tools⁠](https://platform.openai.com/docs/guides/moderation) and guidance so they can support their end users. We [publish](https://openai.com/safety/) what our systems can and can’t do, share [research](https://openai.com/research/index/) and [updates](https://openai.com/news/), and provide a simple way to [report misuse](https://openai.com/form/report-content/).

**We update as we learn**. People are using our systems in new ways every day, and we update our rules to ensure they are not overly restrictive or to better protect our users. We reserve all rights to withhold access where we reasonably believe it necessary to protect our service or users or anyone else. You can [appeal⁠](https://openai.com/transparency-and-content-moderation/#:~:text=determining%20enforcement%20actions.-,Appeals%20process,-If%20we%20take) if you think we have made a mistake enforcing policy, and we will work to make things right. If you’d like to keep up with Usage Policies updates, [complete this form](https://openai.com/form/usage-policy-update/).

**Your use of OpenAI services must follow these Usage Policies:**

* **Protect people**. Everyone has a right to safety and security. So you cannot use our services for:
    * threats, intimidation, harassment, or defamation
    * suicide, self-harm, or disordered eating promotion or facilitation
    * sexual violence or non-consensual intimate content
    * terrorism or violence, including hate-based violence
    * weapons development, procurement, or use, including conventional weapons or CBRNE
    * illicit activities, goods, or services
    * destruction, compromise, or breach of another’s system or property, including malicious or abusive cyber activity or attempts to infringe on intellectual property rights of others
    * real money gambling
    * provision of tailored advice that requires a license, such as legal or medical advice, without appropriate involvement by a licensed professional
    * unsolicited safety testing
    * circumventing our safeguards
    * national security or intelligence purposes without our review and approval
* **Respect privacy**. People are entitled to privacy. So, we don’t allow attempts to compromise the privacy of others, including to aggregate, monitor, profile, or distribute individuals’ private or sensitive information without their authorization. And, you may never use our services for:
    * facial recognition databases without data subject consent
    * real-time remote biometric identification in public spaces
    * use of someone’s likeness, including their photorealistic image or voice, without their consent in ways that could confuse authenticity
    * evaluation or classification of individuals based on their social behavior, personal traits, or biometric data (including social scoring, profiling, or inferring sensitive attributes)
    * inference regarding an individual’s emotions in the workplace and educational settings, except when necessary for medical or safety reasons
    * assessment or prediction of the risk of an individual committing a criminal offense based solely on their personal traits or on profiling
* **Keep minors safe**. Children and teens deserve special protection. Our services are designed to prevent harm and support their well-being, and must never be used to exploit, endanger, or sexualize anyone under 18 years old. [We report](https://openai.com/index/combating-online-child-sexual-exploitation-abuse/) apparent child sexual abuse material and child endangerment to the National Center for Missing and Exploited Children. We prohibit use of our services for:  
    * child sexual abuse material (CSAM), whether or not any portion is AI generated 
    * grooming of minors
    * exposing minors to age-inappropriate content, such as graphic self-harm, sexual, or violent content
    * promoting unhealthy dieting or exercise behavior to minors
    * shaming or otherwise stigmatizing the body type or appearance of minors
    * dangerous challenges for minors
    * underaged sexual or violent roleplay
    * underaged access to age-restricted goods or activities
* **Empower people**. People should be able to make decisions about their lives and their communities. So we don’t allow our services to be used to manipulate or deceive people, to interfere with their exercise of human rights, to exploit people’s vulnerabilities, or to interfere with their ability to get an education or access critical services, including any use for:
    * academic dishonesty
    * deceit, fraud, scams, spam, or impersonation
    * political campaigning, lobbying, foreign or domestic election interference, or demobilization activities
    * automation of high-stakes decisions in sensitive areas without human review
        * critical infrastructure
        * education
        * housing
        * employment
        * financial activities and credit
        * insurance
        * legal
        * medical
        * essential government services
        * product safety components
        * national security
        * migration
        * law enforcement

Changelog
---------

* 2025-10-29: We've updated our Usage Policies to reflect a universal set of policies across OpenAI products and services.
* 2025-01-29: We've updated our Universal Policies to clarify prohibitions under applicable laws.
* 2024-01-10: We've updated our Usage Policies to be clearer and provide more service-specific guidance.
* 2023-02-15: We’ve combined our use case and content policies into a single set of usage policies, and have provided more specific guidance on what activity we disallow in industries we’ve considered high risk.
* 2022-11-09: We no longer require you to register your applications with OpenAI. Instead, we'll be using a combination of automated and manual methods to monitor for policy violations.
* 2022-10-25: Updated App Review process (devs no longer need to wait for approval after submitting as long as they comply with our policies). Moved to an outcomes-based approach and updated Safety Best Practices.
* 2022-06-07: Refactored into categories of applications and corresponding requirements.
* 2022-03-09: Refactored into “App Review”.
* 2022-01-19: Simplified copywriting and article writing/editing guidelines.
* 2021-11-15: Addition of “Content guidelines” section; changes to bullets on almost always approved uses and disallowed uses; renaming document from “Use case guidelines” to “Usage guidelines”.
* 2021-08-04: Updated with information related to code generation.
* 2021-03-12: Added detailed case-by-case requirements; small copy and ordering edits.
* 2021-02-26: Clarified the impermissibility of Tweet and Instagram generators.

Table of contents

* [1\. Misleading Activities](#misleading-activities)
* [2\. Illegal Activities](#illegal-activities)
* [3\. Harmful Activities](#harmful-activities)
* [4\. High Stakes Domains](#high-stakes-domains)
* [5\. Circumventing Restrictions and Safeguards](#circumventing-restrictions-and-safeguards)

Updated: July 17, 2025

Using ChatGPT agent in line with our policies
=============================================

_Note: These guidelines also apply to any ongoing use of the standalone Operator product._

All ChatGPT agent users have agreed to OpenAI’s [Usage Policies⁠](https://openai.com/policies/usage-policies/), Service Terms, and Terms of Use. These policies apply universally to OpenAI services and are designed to ensure safe and responsible usage of AI technology. Below are some tips on how to ensure that usage of ChatGPT agent complies with ethical standards, legal requirements, and OpenAI’s Usage Policies.

You must be at least 18 years old to use ChatGPT agent. 

1\. Misleading Activities
-------------------------

Our policies prohibit using ChatGPT agent to defraud, scam, spam, or mislead others, including:

* Deceiving others for financial gain or manipulation—including phishing, impersonation, fake storefronts, and generating false reviews or testimonials.
* Impersonating individuals or organizations without consent or legal right
* Misrepresenting or concealing the role of AI technology in tasks or interactions

2\. Illegal Activities
----------------------

OpenAI’s terms prohibit any content or usage that violates the law. You may not use ChatGPT agent to infringe on privacy or intellectual property, or facilitate illegal activities, including those targeting minors.

3\. Harmful Activities
----------------------

Agent users are prohibited from creating harmful content or engaging in harmful behaviors or interactions, including:

* Producing, sharing, or facilitating content or experiences that sexualize children
* Bullying, harassment, defamation, or discrimination based on protected attributes
* Inciting or enabling violence

4\. High Stakes Domains
-----------------------

Our policies prohibit using ChatGPT Agent for regulated activities without following applicable laws and rules. Specifically, users should not:

* Make automated decisions in sensitive domains without human involvement, including law enforcement, migration, management of critical infrastructure, safety components of products, essential services, credit, employment, housing, education, social scoring, or insurance
* Automate actions like stock trading or other investment transactions

5\. Circumventing Restrictions and Safeguards
---------------------------------------------

ChatGPT agent users are not allowed to bypass rate limits, restrictions, or safety measures on our services.

Last updated: October 24, 2025

Creating content on Sora in line with our policies
==================================================

Below are some tips to help you create content on Sora responsibly and in compliance with OpenAI’s policies.

1\. Compliance with OpenAI’s Usage Policies
-------------------------------------------

All ChatGPT and Sora users have agreed to OpenAI’s Usage Policies, Service Terms, and Terms of Use. These policies apply universally to OpenAI services and are designed to ensure safe and responsible usage of AI technology. You can review OpenAI’s Usage Policies [here⁠](https://openai.com/policies/usage-policies/).

2\. Sora Distribution Guidelines
--------------------------------

Additionally, content deemed inappropriate for all users may be removed from the Sora Feed and other sharing platforms, such as user galleries and character cameos, in accordance with our Sora Distribution Guidelines. This includes:

* Graphic sexual content;
* Graphic violence or content promoting violence;
* Extremist propaganda;
* Hateful content;
* Targeted political persuasion;
* Content that promotes or depicts self harm or disordered eating;
* Unhealthy dieting or exercise behaviors;
* Appearance-based critiques or comparisons;
* Bullying content;
* Dangerous challenges likely to be imitated by minors;
* Content glorifying depression;
* Promotion of age-restricted goods or activities including illegal drugs or harmful substances; and 
* Low quality content where the primary purpose is engagement bait;
* Content that recreates the likeness of living public figures without their consent;
* Content that may infringe on the intellectual property rights of others.

3\. Reporting Violations
------------------------

If you encounter content that you believe violates any of our policies, [please report it immediately⁠](https://openai.com/form/report-content/). We take all violations seriously and will review reported content for compliance with our terms and the broader OpenAI Usage Policies and Sora Distribution Guidelines.

Updated: November 14, 2022

Sharing & publication policy
============================

Social media, livestreaming, and demonstrations
-----------------------------------------------

To mitigate the possible risks of AI-generated content, we have set the following policy on permitted sharing.

Posting your own prompts or completions to social media is generally permissible, as is livestreaming your usage or demonstrating our products to groups of people. Please adhere to the following:

* Manually review each generation before sharing or while streaming.
* Attribute the content to your name or your company.
* Indicate that the content is AI-generated in a way no user could reasonably miss or misunderstand.
* Do not share content that violates our [Content Policy⁠](https://openai.com/policies/usage-policies/) or that may offend others.
* If taking audience requests for prompts, use good judgment; do not input prompts that might result in violations of our [Content Policy⁠](https://openai.com/policies/usage-policies/).

If you would like to ensure the OpenAI team is aware of a particular completion, you may email us or use the reporting tools within Playground.

* Recall that you are interacting with the raw model, which means we do not filter out biased or negative responses. (Also, you can read more about implementing our [free Moderation endpoint⁠](https://platform.openai.com/docs/models/moderation) here.)

Content co-authored with the OpenAI API
---------------------------------------

Creators who wish to publish their first-party written content (e.g., a book, compendium of short stories) created in part with the OpenAI API are permitted to do so under the following conditions:

* The published content is attributed to your name or company.
* The role of AI in formulating the content is clearly disclosed in a way that no reader could possibly miss, and that a typical reader would find sufficiently easy to understand.
* Topics of the content do not violate OpenAI’s [Content Policy⁠](https://openai.com/policies/usage-policies/) or [Terms of Use⁠](https://openai.com/policies/terms-of-use/), e.g., are not related to adult content, spam, hateful content, content that incites violence, or other uses that may cause social harm.
* We kindly ask that you refrain from sharing outputs that may offend others.

For instance, one must detail in a Foreword or Introduction (or some place similar) the relative roles of drafting, editing, etc. People should not represent API-generated content as being wholly generated by a human or wholly generated by an AI, and it is a human who must take ultimate responsibility for the content being published.

Here is some stock language you may use to describe your creative process, provided it is accurate:

> The author generated this text in part with GPT‑3, OpenAI’s large-scale language-generation model. Upon generating draft language, the author reviewed, edited, and revised the language to their own liking and takes ultimate responsibility for the content of this publication.

Research
--------

We believe it is important for the broader world to be able to evaluate our research and products, especially to understand and improve potential weaknesses and safety or bias problems in our models. Accordingly, we welcome research publications related to the OpenAI API.

* In some cases, we may want to highlight your work internally and/or externally.
* In others, such as publications that pertain to security or misuse of the API, we may want to take appropriate actions to protect our users.
* If you notice any safety or security issues with the API in the course of your research, we ask that you please submit these immediately through our [Coordinated Vulnerability Disclosure Program⁠](https://openai.com/policies/coordinated-vulnerability-disclosure-policy/).

Researcher Access Program
-------------------------

There are a number of research directions we are excited to explore with the OpenAI API. If you are interested in the opportunity for subsidized access, please provide us with details about your research use case on the [Researcher Access Program application⁠](https://openai.com/form/researcher-access-program/).

In particular, we consider the following to be especially important directions, though you are free to craft your own direction:

* **Alignment**: How can we understand what objective, if any, a model is best understood as pursuing? How do we increase the extent to which that objective is aligned with human preferences, such as via prompt design or fine-tuning?
* **Fairness and representation**: How should performance criteria be established for fairness and representation in language models? How can language models be improved in order to effectively support the goals of fairness and representation in specific, deployed contexts?
* **Interdisciplinary research**: How can AI development draw on insights from other disciplines such as philosophy, cognitive science, and sociolinguistics?
* **Interpretability and transparency**: How do these models work, mechanistically? Can we identify what concepts they’re using, or extract latent knowledge from the model, make inferences about the training procedure, or predict surprising future behavior?
* **Misuse potential**: How can systems like the API be misused? What sorts of “red teaming” approaches can we develop to help us and other AI developers think about responsibly deploying technologies like this?
* **Model exploration**: Models like those served by the API have a variety of capabilities which we have yet to explore. We’re excited by investigations in many areas including model limitations, linguistic properties, commonsense reasoning, and potential uses for many other problems.
* **Robustness**: Generative models have uneven capability surfaces, with the potential for surprisingly strong and surprisingly weak areas of capability. How robust are large generative models to “natural” perturbations in the prompt, such as phrasing the same idea in different ways or with or without typos? Can we predict the kinds of domains and tasks for which large generative models are more likely to be robust (or not robust), and how does this relate to the training data? Are there techniques we can use to predict and mitigate worst-case behavior? How can robustness be measured in the context of few-shot learning (e.g., across variations in prompts)? Can we train models so that they satisfy safety properties with a very high level of reliability, even under adversarial inputs?

Please note that due to a high volume of requests, it takes time for us to review these applications and not all research will be prioritized for subsidy. We will only be in touch if your application is selected for subsidy.